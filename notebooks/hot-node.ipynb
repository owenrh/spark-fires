{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c07357-4312-4416-b659-576b7cdfda3e",
   "metadata": {},
   "source": [
    "![title](img/this-is-fine-spark.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947cfb21-32d6-4b1e-b88b-e57400447e74",
   "metadata": {},
   "source": [
    "## ðŸ”¥ Spark fires ðŸ”¥  - Hot node (stragglers) scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc26280-bd7d-49f1-9ac3-0fae6979fb15",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b39306-8046-4f1a-a33d-7913a6b6b7f3",
   "metadata": {},
   "source": [
    "In this scenario we create a situation in which one of our executors is processing data much more slowly than the other executors. This is often seen in multi-tenant clusters where load is rarely, if ever, perfectly balanced across the cluster.\n",
    "\n",
    "You might also hit this scenario if you are running multiple Spark applications on a single tenant cluster, where the application load is unevenly distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfdf77a-500d-4801-895b-832785a1e929",
   "metadata": {},
   "source": [
    "### Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36802afa-3c42-4ed4-a064-3e43df8119d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder.master(\"spark://spark:7077\")\n",
    "    # .config(\"spark.eventLog.enabled\", \"true\")\n",
    "    # .config(\"spark.eventLog.dir\", \"/data/tmp/spark-events\")\n",
    "    .config(\"spark.locality.wait\", \"0\")  # -- change 2 - improves speed of task redistribution\n",
    "    .appName(\"spark-fires-hot-node\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e838f9-41ce-4c59-81e6-715a6dccafef",
   "metadata": {},
   "source": [
    "### Create some fake data to process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa656ccf-e817-4668-9560-1e764dcdb7b9",
   "metadata": {},
   "source": [
    "Note, we can tweak the `num_partitions` to help reduce the impact of our hot-node. \n",
    "\n",
    "Try running with the original setting and then adjusted setting, perhaps play around with your own values. You should see ~ 2x speed up. Whoop, whoop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e62198-1e64-4529-9049-a9df750e9992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "num_partitions = 6\n",
    "# num_partitions = 18  # -- change 1 - increase no. of partitions to allow Spark to redistribute partition tasks across executors\n",
    "\n",
    "df = spark.range(0, 7200).repartition(num_partitions).cache()\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c993566-5c9a-43a4-bd21-7f80aa070677",
   "metadata": {},
   "source": [
    "### Starting the fire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a210e2-eada-4060-a32d-02a881b472b2",
   "metadata": {},
   "source": [
    "_Note, we use `sleep` as a cheat to simulate our slower processing on our hot node._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628fc1f-631d-48c2-9f66-d1b891a4cf3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from time import sleep\n",
    "import os\n",
    "\n",
    "def process_partition(iterator):\n",
    "    for item in iterator:\n",
    "        if 'HOT_NODE' in os.environ:\n",
    "            sleep(0.05)\n",
    "        else:\n",
    "            sleep(0.01)\n",
    "            \n",
    "        yield item\n",
    "\n",
    "mapped = df.rdd.mapPartitions(process_partition).toDF()\n",
    "mapped.write.format(\"parquet\").mode('overwrite').save(\"/data/range_nums\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dddce92-fcbd-4e34-ae56-dac5029c6d03",
   "metadata": {},
   "source": [
    "### Putting the fire out  ðŸ”¥ðŸ”¥ðŸ”¥ ðŸš’ ðŸš’ ðŸš’ ðŸ§¯ðŸ§¯ðŸ§¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7671950-7510-412d-8f5c-f893b5a20777",
   "metadata": {},
   "source": [
    "First run through you should see an execution time of ~ 60 seconds for the first. If you look at the Spark UI on http://localhost:4040/ and when we dig through into the stage tasks we can see we have two stragglering tasks on our 'hot node'.\n",
    "\n",
    "Oof, what can we do? Let's take a look at some levers we can pull on:\n",
    "1. Firstly, we can increase the number of partitions on our data, see `-- change 1` above. This gives Spark more tasks to play with, which it will redistribute to the executors which have completed their work, our 'cool' executors. This change should give us a **30% speed improvement** straight off of the bat.\n",
    "2. Next, we can tune the Spark configuration by setting the `spark.locality.wait` to 0 seconds, see `-- change 2`. Make this change and restart the kernel. This will make Spark aggressively move work to different executors rather than waiting a bit longer to process the data locally. Data locality is an important concept and trade-off. But with cloud data processing data locality is less relevant than Hadoop environments. This final change should give us a **~ 3x speed improvement**, which is not too shabby.\n",
    "\n",
    "_One caveat to keep in mind: the Docker setup is all on a single machine, so running locally like this you are not seeing normal network latency and transfer speeds, which will add a small amount of overhead._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a030cf-0283-471d-8940-0ec81f0fe700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77ea89-4ace-432e-9d7e-5bcb8ad73e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51777cb0-1c66-4e86-8cba-2ec901d9f02a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
